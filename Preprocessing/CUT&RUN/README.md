# CUT&RUN processing

Here, you can find a detailed description of how CUT&RUN data were processed in this project.

## Dependencies

* [Trim Galore](https://github.com/FelixKrueger/TrimGalore)
* [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
* [Bowtie2](https://bowtie-bio.sourceforge.net/bowtie2/index.shtml)
* [samtools](http://www.htslib.org/download/)
* [sambamba](https://github.com/biod/sambamba)
* [deepTools](https://deeptools.readthedocs.io/en/latest/)
* [macs2](https://github.com/macs3-project/MACS)
* [csaw (R package)](https://bioconductor.org/packages/release/bioc/html/csaw.html)
* [GenomicRanges (R package)](https://bioconductor.org/packages/release/bioc/html/GenomicRanges.html)
* [DESeq2 (R package)](https://bioconductor.org/packages/release/bioc/html/DESeq2.html)


## Summary of the workflow

1. **Trimming and Quality**: Trim Galore and FastQC
2. **Alignment**: Bowtie2*
3. **Filtering**: samtools and sambamba
4. **Coverage**: deepTools
5. **Generating Peakmatrix**: csaw and GenomicRanges
6. **Generating Background Matrix**: csaw and GenomicRanges
* with CUT&RUN-specific alignment parameters
7. **ChromHMM & ChromTime**

A detailed description of how steps 1-4 were performed can be found [here](https://github.com/JavierreLab/liCHiC/tree/main/3.ChIPseq%20Processing), the GitHub page associated to Tomás-Daza, L *et al.* Low input capture Hi-C (liCHi-C) identifies promoter-enhancer interactions at high-resolution. *Nature Communications* **14**, 268 (2023). [https://doi.org/10.1038/s41467-023-35911-8](https://doi.org/10.1038/s41467-023-35911-8)
We follow mostly the same logic as for a ChIP-seq experiment.

## 2. Alignment*

The alignment step is the main point of divergence from the ChIP-seq preprocessing pipeline. In particular, we enable the --dovetail option in Bowtie2 to retain paired-end reads in which mates overlap. Such overlapping pairs are expected in CUT&RUN data due to the generation of very short DNA fragments and would otherwise be discarded by default Bowtie2 filtering. Retaining these reads is therefore essential to avoid the systematic loss of valid CUT&RUN signal.

```bash
bowtie2 -x $INDEX -1 $FASTQ1 -2 $FASTQ2 --very-sensitive-local --no-unal --no-mixed --no-discordant -k 2 --phred33 -I 10 -X 700 --dovetail -p $THREADS -S $OUTDIR/$NAME.sam
```
## 7. ChromHMM & ChromTime

### Overview

This section describes the complete chromatin segmentation workflow performed after CUT&RUN preprocessing, starting from filtered BAM files obtained after alignment and filtering steps.

Genome assembly: GRCh38  
ChromHMM bin size: 200 bp (default)  
Final model: 15 chromatin states  

---

### 7.1. Starting input files

We started from **filtered BAM files** generated after alignment and filtering steps.

Replicates strategy:

- **ChromTime (narrow marks)** → replicates were supermerged per cell type.
- **ChromHMM broad mark binarization** → all replicates were used individually.
- IgG was used as background control in all relevant steps.

---

### 7.2. ChromTime Peak Calling (Narrow Histone Marks)

For narrow histone marks **(H3K27ac and H3K4me3)**, we performed peak calling using ChromTime, a trajectory-aware peak caller designed to model temporal dynamics.

#### 7.2.1 Strategy

- **Supermerged BAM files** (per cell type) were used.
- Background: supermerged IgG BAM per cell type.
- ChromTime was run using a tab-separated configuration file.
- Two differentiation trajectories were modeled:
  - Trajectory ending at memB
  - Trajectory ending at PC

After running both trajectories:

1. Peaks were extracted per cell type.
2. The **intersection of peaks** from both trajectories was computed.
3. The resulting intersected BED files were used for ChromHMM binarization.

#### ChromTime Command

```bash

python ChromTime.py -i $Path_to_ChromTime_input_table -o $Path_to_ChromTime_output -t 8 -g grc38 -p ct -q 0.01 --q-value-seed 0.01 --p-value-extend 0.01

```

---

### 7.3. ChromHMM Binarization (200 bp resolution)

We performed binarization using ChromHMM at the default 200 bp resolution, following the official manual: https://ernstlab.github.io/ChromHMM/ChromHMM_manual.pdf

#### 7.3.1 Broad Histone Marks

For broad marks **(H3K4me1,H3K27me3,H3K9me3)** we used **BinarizeBam** directly on filtered BAM files:

```
java -mx4000M -jar ChromHMM.jar BinarizeBam \
  $chr_length_file \
  $samples_directory \
  $cell_mark_file_broad \
  $output_binary_directory

```

#### 7.3.2 Narrow Histone Marks

For narrow marks **(H3K27ac and H3K4me3)**, we binarized using **peak files** generated by ChromTime:

```
java -mx4000M -jar ChromHMM.jar BinarizeBed -peaks \
  $chr_length_file \
  $samples_directory_intersect_peaks_ChromTime \
  $cell_mark_file_narrow \
  $output_binary_directory

```

#### 7.3.3 Generating Peak BED Files from Binarization

After binarization, we generated for each histone mark and cell type a corresponding **peaks BED file** for downstream analyses.

Briefly, we identified all bins marked as present (`1`) for a given histone mark and reconstructed their genomic coordinates based on the fixed ChromHMM bin size (200 bp).

For each positive bin:

- The start coordinate (0-based) was calculated as: start_position = (bin_index - 1) * 200
- The end coordinate (1-based) was calculated as: end_position = start_position + 200

Where:

- `bin_index` corresponds to the row number of the bin in the binarized file.


#### 7.3.4 Merging Narrow and Broad binarizations

For each chromosome and each cell type, we merged the binarization output files from Narrow and Broad histone marks into an unified dataset, which was used for model learning.

### 7.4. ChromHMM Model Learning

Using the merged binarized files, we trained a ChromHMM model with **15 states**:

```
java -mx20000M -jar ChromHMM.jar LearnModel \
  -p 96 \
  $output_binary_directory \
  $output_model_directory \
  15 \
  GRCh38

```
